{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0049af2",
   "metadata": {},
   "source": [
    "# TF-IDF weighting retrieval implementation for TREC-DL 2020 Passage Ranking task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddcb145d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "import scipy.sparse as scipy_sparse\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a17dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSMARCO_PASSAGE_COLLECTION=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/pyserini/collections/msmarco-passage/collection.tsv\"\n",
    "\n",
    "STEMMED_DOCS_FILE=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/ia368v_dd_class_02/indexes/tempfile.pkl\"\n",
    "\n",
    "STEMMED_DOCS_FILE_FORMAT=\"{}_{}.pkl\"\n",
    "STEMMED_DOCS_FOLDER=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/ia368v_dd_class_02/indexes\"\n",
    "\n",
    "REVERSED_INDEX_FOLDER=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/ia368v_dd_class_02/indexes\"\n",
    "REVERSED_INDEX_FILE_FORMAT=\"reversed_index_TREC-DL_2020_{}.pkl\"\n",
    "\n",
    "REVERSED_INDEX_FILE=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/ia368v_dd_class_02/indexes/reversed_index_TREC-DL_2020_complete.pkl\"\n",
    "\n",
    "TOKENS_COUNT_FILE=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/ia368v_dd_class_02/indexes/tokens_count_TREC-DL_2020.pkl\"\n",
    "\n",
    "TFIDF_FOLDER=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/ia368v_dd_class_02/indexes\"\n",
    "TFIDF_FILE_FORMAT=\"tfidf_TREC-DL_2020_{}.pkl\"\n",
    "\n",
    "TFIDF_FILE=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/ia368v_dd_class_02/indexes/tfidf_TREC-DL_2020_complete.pkl\"\n",
    "\n",
    "TREC_DL_2020_QUERIES=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/pyserini/collections/trec-dl_2020-passage/msmarco-test2020-queries.tsv\"\n",
    "TREC_DL_2020_QRELS=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/pyserini/collections/trec-dl_2020-passage/2020qrels-pass.txt\"\n",
    "\n",
    "TREC_DL_2020_RUN_FORMAT=\"TREC_DL_2020_tfidf_run_{}.tsv\"\n",
    "TREC_DL_2020_RUN_FOLDER=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/ia368v_dd_class_02/runs\"\n",
    "\n",
    "TREC_EVAL_FULLPATH=\"/mnt/0060f889-4c27-409b-b0de-47f5427515e3/unicamp/ia368v_dd/pyserini/tools/eval/trec_eval.9.0.4/trec_eval\"\n",
    "\n",
    "NUMBER_OF_DOCS=8841822\n",
    "\n",
    "PARTIAL_STEMMED_DOCS_COUNT=1000000\n",
    "\n",
    "PARTIAL_TFIDF_TOKENS_COUNT=500000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5cc92",
   "metadata": {},
   "source": [
    "## Text preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d17c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuation = set(string.punctuation)\n",
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ce966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocess_text(which_text):\n",
    "\n",
    "    all_tokens = nltk.word_tokenize(which_text.lower())\n",
    "    cleaned_tokens = [token for token in all_tokens if token not in stop_words and token not in punctuation]\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in cleaned_tokens]\n",
    "\n",
    "    return stemmed_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e562299",
   "metadata": {},
   "source": [
    "## If has already computed the tf-idf values, load then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5154ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TFIDF_FILE, 'rb') as inputFile:\n",
    "    all_tfidfs = pickle.load(inputFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ab91b",
   "metadata": {},
   "source": [
    "## ...otherwise, compute the td-idf of each document in the corpus\n",
    "\n",
    "Since we already have the reversed index built on the same corpus with the terms count in each document (this was done in the [boolean retrieval notebook](https://github.com/eduseiti/ia368v_dd_class_02/blob/main/boolean_retrieval_TREC-DL_2020.ipynb)), we can leverage that to compute the tf-idf or each document.\n",
    "\n",
    "However, we don't have in hand the total number of terms/tokens for each document. Hence, need to compute it first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f926989",
   "metadata": {},
   "source": [
    "### If has already computed the total number of tokens in each document, read that information...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bbe673",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TOKENS_COUNT_FILE, 'rb') as inputFile:\n",
    "    tokens_per_document = pickle.load(inputFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf54b4f9",
   "metadata": {},
   "source": [
    "### ...otherwise, start computing it\n",
    "\n",
    "Once again, we will build on the results of the [boolean retrieval notebook](https://github.com/eduseiti/ia368v_dd_class_02/blob/main/boolean_retrieval_TREC-DL_2020.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8574aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_number_of_terms_per_document(file_index):\n",
    "    \n",
    "    total_number_of_terms = {}\n",
    "    \n",
    "    with open(os.path.join(STEMMED_DOCS_FOLDER, STEMMED_DOCS_FILE_FORMAT.format(\"temp\", file_index)), \"rb\") as inputFile:\n",
    "        temp_file = pickle.load(inputFile)\n",
    "\n",
    "        read_documents_index = temp_file['doc_ids']\n",
    "        stemmed_documents = temp_file['stemmed_docs']                \n",
    "\n",
    "    print(\"Document range: {} until {}\".format(read_documents_index[0], read_documents_index[-1]))\n",
    "    \n",
    "    for doc_index in range(len(stemmed_documents)):\n",
    "        total_number_of_terms[int(read_documents_index[doc_index])] = len(stemmed_documents[doc_index])\n",
    "    \n",
    "    return total_number_of_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=3) as pool:\n",
    "    terms_count = pool.map(compute_total_number_of_terms_per_document, range(0, NUMBER_OF_DOCS // PARTIAL_STEMMED_DOCS_COUNT + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece4d33",
   "metadata": {},
   "source": [
    "### Merge into a single dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79532d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_per_document = terms_count[0]\n",
    "\n",
    "for partial_dic in terms_count[1:]:\n",
    "    for document, count in partial_dic.items():\n",
    "        tokens_per_document[document] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tokens_per_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del terms_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51771e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TOKENS_COUNT_FILE, 'wb') as outputFile:\n",
    "    pickle.dump(tokens_per_document, outputFile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb912aa0",
   "metadata": {},
   "source": [
    "### Load the reversed index to get the term counts per document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a447b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(REVERSED_INDEX_FILE, 'rb') as inputFile:\n",
    "    reversed_indexes = pickle.load(inputFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f10997",
   "metadata": {},
   "source": [
    "### Now, process each term to compute the related documents tf-idf value\n",
    "\n",
    "Once again, due to RAM limitations, the processing will first create partial tfidf file which will be concatenated after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d446a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(token, verbose=False):\n",
    "    \n",
    "    token_tdidfs = lil_matrix((1, NUMBER_OF_DOCS), dtype=np.float32)\n",
    "    \n",
    "    related_docs = reversed_indexes[token].nonzero()\n",
    "    \n",
    "    if verbose:\n",
    "        print(related_docs)\n",
    "    \n",
    "    if type(reversed_indexes[token]) is scipy_sparse._csr.csr_matrix:\n",
    "        related_docs_counts = np.array(reversed_indexes[token][related_docs])[0]\n",
    "    else:\n",
    "        related_docs_counts = np.array(reversed_indexes[token][related_docs].todense())[0]\n",
    "\n",
    "    if verbose:\n",
    "        print(related_docs_counts)\n",
    "\n",
    "    term_idf = np.log(NUMBER_OF_DOCS / len(related_docs[1]))\n",
    "\n",
    "    if verbose:\n",
    "        print(term_idf)\n",
    "    \n",
    "    for i, doc in enumerate(related_docs[1]):\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"i={}, doc={}\".format(i, doc))\n",
    "        \n",
    "        doc_tf = related_docs_counts[i] / tokens_per_document[doc]\n",
    "        \n",
    "        if verbose:\n",
    "            print(doc_tf)\n",
    "        \n",
    "        token_tdidfs[0, doc] = doc_tf * term_idf\n",
    "        \n",
    "    return token_tdidfs.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidfs_for_tokens(tokens_list, part_index):\n",
    "    \n",
    "    print(\"len(tokens_list)={}, part_index={}\".format(len(tokens_list), part_index))\n",
    "    \n",
    "    computed_tfidfs = {}\n",
    "    \n",
    "    for token in tokens_list:\n",
    "        computed_tfidfs[token] = compute_tfidf(token)\n",
    "        \n",
    "    with open(os.path.join(TFIDF_FOLDER, TFIDF_FILE_FORMAT.format(part_index)), 'wb') as outputFile:\n",
    "        pickle.dump(computed_tfidfs, outputFile, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f602f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = list(reversed_indexes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c070771a",
   "metadata": {},
   "source": [
    "### Break the existing tokens set into chunks...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622da9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_groups = []\n",
    "\n",
    "for i in range(len(reversed_indexes) // PARTIAL_TFIDF_TOKENS_COUNT + 1):\n",
    "    token_groups.append(all_tokens[i * PARTIAL_TFIDF_TOKENS_COUNT:(i * PARTIAL_TFIDF_TOKENS_COUNT + PARTIAL_TFIDF_TOKENS_COUNT)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473aa577",
   "metadata": {},
   "source": [
    "### ...and process them in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "\n",
    "with Pool(processes=2) as pool:\n",
    "    results = pool.starmap(compute_tfidfs_for_tokens, zip(token_groups, range(len(token_groups))))\n",
    "    \n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea28108",
   "metadata": {},
   "source": [
    "### Now merge the partial tfidfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(TFIDF_FOLDER, TFIDF_FILE_FORMAT.format(0)), 'rb') as inputFile:\n",
    "    all_tfidfs = pickle.load(inputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf45994",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 8):\n",
    "    with open(os.path.join(TFIDF_FOLDER, TFIDF_FILE_FORMAT.format(i)), 'rb') as inputFile:\n",
    "        partial_tfidfs = pickle.load(inputFile)\n",
    "        \n",
    "    for token, token_docs in partial_tfidfs.items():\n",
    "        all_tfidfs[token] = token_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695197d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_tfidfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TFIDF_FILE, 'wb') as outputFile:\n",
    "    pickle.dump(all_tfidfs, outputFile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84912ff",
   "metadata": {},
   "source": [
    "## Run the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ba3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_index = []\n",
    "query_text = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fd399a",
   "metadata": {},
   "source": [
    "### Read all the queries in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b010a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(TREC_DL_2020_QUERIES, 'r', encoding=\"utf-8\") as inputFile:\n",
    "    for line in inputFile:\n",
    "        query_data = line.split('\\t')\n",
    "        \n",
    "        query_index.append(query_data[0])\n",
    "        query_text.append(query_data[1])\n",
    "\n",
    "len(query_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b22b0",
   "metadata": {},
   "source": [
    "### Preprocess the queries the same way as the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e8f00e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Pool(processes=8) as pool:\n",
    "    stemmed_queries = pool.map(test_preprocess_text, query_text)\n",
    "\n",
    "len(stemmed_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b3dadb",
   "metadata": {},
   "source": [
    "### Find the query matches\n",
    "\n",
    "Here each query/document score will be computed summing all the tf-idf values of the query/document common terms. This is the [tf-idf weighting scheme](https://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html#:~:text=The%20tf%2Didf%20weighting%20scheme,power%20to%20those%20documents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8351fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_related_documents(stemmed_query, only_all_terms=False):\n",
    "    \n",
    "    related_documents = {}\n",
    "    \n",
    "    for token in stemmed_query:\n",
    "        if token in all_tfidfs:\n",
    "            \n",
    "#             print(token)\n",
    "            \n",
    "            related_docs = all_tfidfs[token].nonzero()\n",
    "            \n",
    "            if type(all_tfidfs[token]) is scipy_sparse._csr.csr_matrix:\n",
    "                related_docs_scores = np.array(all_tfidfs[token][related_docs])[0]\n",
    "            else:\n",
    "                related_docs_scores = np.array(all_tfidfs[token][related_docs].todense())[0]\n",
    "            \n",
    "            for i, doc in enumerate(related_docs[1]):\n",
    "                if doc not in related_documents:\n",
    "                    related_documents[doc] = 0\n",
    "\n",
    "                related_documents[doc] += related_docs_scores[i]\n",
    "            \n",
    "    return related_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae8e3458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : ['aziz', 'hashim']\n",
      "0.002541065216064453\n",
      "\n",
      "1 : ['rep', 'scalis']\n",
      "0.022538185119628906\n",
      "\n",
      "2 : ['kill', 'nichola', 'ii', 'russia']\n",
      "0.20097017288208008\n",
      "\n",
      "3 : ['own', 'barnhart', 'crane']\n",
      "0.06723451614379883\n",
      "\n",
      "4 : ['said', 'one', 'make', 'feel', 'inferior']\n",
      "3.1524338722229004\n",
      "\n",
      "5 : ['sing', 'monk', 'theme', 'song']\n",
      "0.14412951469421387\n",
      "\n",
      "6 : ['highest', 'career', 'passer', 'rate', 'nfl']\n",
      "0.6446554660797119\n",
      "\n",
      "7 : ['hunter', 'pattern', 'shotgun']\n",
      "0.08183884620666504\n",
      "\n",
      "8 : ['place', 'scalp', 'feel', 'sore']\n",
      "0.8172321319580078\n",
      "\n",
      "9 : ['pete', 'rose', 'ban', 'hall', 'fame']\n",
      "0.10611796379089355\n",
      "\n",
      "10 : ['thoma', 'cooley']\n",
      "0.033742666244506836\n",
      "\n",
      "11 : ['definit', 'endors']\n",
      "0.384899377822876\n",
      "\n",
      "12 : ['hormon', 'increas', 'calcium', 'level', 'blood']\n",
      "1.1790614128112793\n",
      "\n",
      "13 : ['defin', 'geon']\n",
      "0.1741039752960205\n",
      "\n",
      "14 : ['amazon', 'rainforest', 'locat']\n",
      "0.5880796909332275\n",
      "\n",
      "15 : ['four', 'forc', 'act', 'airplan', 'equilibrium']\n",
      "0.7087488174438477\n",
      "\n",
      "16 : ['defin', 'pareto', 'chart', 'statist']\n",
      "0.3417983055114746\n",
      "\n",
      "17 : ['year', 'timberwolv', 'found']\n",
      "1.7341885566711426\n",
      "\n",
      "18 : ['year', 'knee', 'deep', 'come', 'funkadel']\n",
      "1.7838799953460693\n",
      "\n",
      "19 : ['defin', 'defin', 'gallow']\n",
      "0.21700429916381836\n",
      "\n",
      "20 : ['tissu', 'compos', 'hypodermi']\n",
      "0.21799755096435547\n",
      "\n",
      "21 : ['time', 'zone', 'st', 'paul', 'minnesota']\n",
      "1.4952921867370605\n",
      "\n",
      "22 : ['best', 'way', 'get', 'cloth', 'white']\n",
      "2.251939535140991\n",
      "\n",
      "23 : ['temperatur', 'humid', 'dri', 'sausag']\n",
      "0.4542858600616455\n",
      "\n",
      "24 : ['mental', 'ill']\n",
      "0.117919921875\n",
      "\n",
      "25 : ['medium', 'radio', 'wave', 'travel']\n",
      "0.3343031406402588\n",
      "\n",
      "26 : ['languag', 'craith', 'film']\n",
      "0.26576995849609375\n",
      "\n",
      "27 : ['un', 'fao']\n",
      "0.00989985466003418\n",
      "\n",
      "28 : ['distanc', 'flat', 'rock', 'michigan', 'detroit', 'michigan']\n",
      "0.31888270378112793\n",
      "\n",
      "29 : ['shakespear', \"'s\", 'theatr', 'call']\n",
      "2.9379851818084717\n",
      "\n",
      "30 : ['reba', 'mcentir', \"'s\", 'net', 'worth']\n",
      "2.3796584606170654\n",
      "\n",
      "31 : ['call', 'blood', 'becom', 'thin']\n",
      "1.5791730880737305\n",
      "\n",
      "32 : ['meat', 'group']\n",
      "0.4565277099609375\n",
      "\n",
      "33 : ['conform', 'definit']\n",
      "0.37552785873413086\n",
      "\n",
      "34 : ['chaff', 'flare']\n",
      "0.006963253021240234\n",
      "\n",
      "35 : ['nonconform', 'earth', 'scienc']\n",
      "0.239790678024292\n",
      "\n",
      "36 : ['unauthor', 'act', 'write', 'mean']\n",
      "1.0561130046844482\n",
      "\n",
      "37 : ['word', 'potteri', 'mean']\n",
      "0.9834105968475342\n",
      "\n",
      "38 : ['provis', 'mean']\n",
      "0.7096710205078125\n",
      "\n",
      "39 : ['plank', 'owner', 'mean']\n",
      "0.793982982635498\n",
      "\n",
      "40 : ['distraint', 'mean']\n",
      "0.6978540420532227\n",
      "\n",
      "41 : ['psycholog', 'screen', 'consist', 'egg', 'donor']\n",
      "0.4462568759918213\n",
      "\n",
      "42 : ['cari', 'detect', 'system']\n",
      "0.677849292755127\n",
      "\n",
      "43 : ['discrimin', 'workplac', 'oklahoma', 'citi']\n",
      "0.4586038589477539\n",
      "\n",
      "44 : ['major', 'polit', 'parti', 'great', 'britain', 'select', 'appli']\n",
      "1.3070766925811768\n",
      "\n",
      "45 : ['symptom', 'kid']\n",
      "0.38178229331970215\n",
      "\n",
      "46 : ['amino', 'produc', 'carnitin']\n",
      "0.37572264671325684\n",
      "\n",
      "47 : ['adob', 'need', 'creat', 'extern', 'link', 'pdf', 'document']\n",
      "1.5837061405181885\n",
      "\n",
      "48 : ['walmart', 'phone', 'number', 'linton']\n",
      "0.787926435470581\n",
      "\n",
      "49 : ['briefli', 'describ', 'lung', 'function']\n",
      "0.5267534255981445\n",
      "\n",
      "50 : ['rout', 'number', 'save', 'bank', 'main']\n",
      "1.2311985492706299\n",
      "\n",
      "51 : ['reign', 'definit']\n",
      "0.37374234199523926\n",
      "\n",
      "52 : ['outmaneuv', 'definit']\n",
      "0.36141276359558105\n",
      "\n",
      "53 : ['number', 'employe', 'disa', 'global', 'solut']\n",
      "1.008608341217041\n",
      "\n",
      "54 : ['ms', 'symptom', 'ms']\n",
      "0.32695627212524414\n",
      "\n",
      "55 : ['monk', 'mean']\n",
      "0.6893281936645508\n",
      "\n",
      "56 : ['mean', 'shebang']\n",
      "0.6874921321868896\n",
      "\n",
      "57 : ['medicin', 'toradol', 'narcot']\n",
      "0.12102866172790527\n",
      "\n",
      "58 : ['healthcar', 'iihi', 'stand']\n",
      "0.17116856575012207\n",
      "\n",
      "59 : ['much', 'passport']\n",
      "0.5220637321472168\n",
      "\n",
      "60 : ['much', 'cornstarch', 'need', 'thicken']\n",
      "1.3775265216827393\n",
      "\n",
      "61 : ['mani', 'year', 'go', 'school', 'becom', 'anesthesiologist']\n",
      "3.040408134460449\n",
      "\n",
      "62 : ['mani', 'son', 'robert', 'kraft']\n",
      "1.0236890316009521\n",
      "\n",
      "63 : ['mani', 'brick', 'per', 'wall']\n",
      "1.5588102340698242\n",
      "\n",
      "64 : ['long', 'cook', 'potato', 'wedg', 'oven', 'frozen']\n",
      "0.7198281288146973\n",
      "\n",
      "65 : ['averag', 'annual', 'incom', 'data', 'analyst']\n",
      "1.1769623756408691\n",
      "\n",
      "66 : ['long', 'stay', 'contagi', 'flu']\n",
      "0.5899882316589355\n",
      "\n",
      "67 : ['long', 'cook', 'artichok']\n",
      "0.6180205345153809\n",
      "\n",
      "68 : ['long', 'hormon', 'headach', 'last']\n",
      "0.9140782356262207\n",
      "\n",
      "69 : ['vitamin', 'c', 'help']\n",
      "0.8652637004852295\n",
      "\n",
      "70 : ['granul', 'tissu', 'start']\n",
      "0.6583271026611328\n",
      "\n",
      "71 : ['hotshot', 'member']\n",
      "0.22296524047851562\n",
      "\n",
      "72 : ['holiday', 'definit']\n",
      "0.41875576972961426\n",
      "\n",
      "73 : ['head', 'basketbal', 'coach', 'texa']\n",
      "0.32650089263916016\n",
      "\n",
      "74 : ['geneva', 'il', 'median', 'sale', 'price']\n",
      "0.5550415515899658\n",
      "\n",
      "75 : ['flyover', 'definit']\n",
      "0.3621242046356201\n",
      "\n",
      "76 : ['first', 'eagl', 'credit', 'union', 'rout', 'number']\n",
      "1.9182751178741455\n",
      "\n",
      "77 : ['antibiot', 'kind', 'infect']\n",
      "0.38684868812561035\n",
      "\n",
      "78 : ['embed', 'payment', 'definit']\n",
      "0.4853980541229248\n",
      "\n",
      "79 : ['dx', 'code', 'thorac', 'outlet', 'syndrom']\n",
      "0.2944624423980713\n",
      "\n",
      "80 : ['low', 'vitamin', 'caus', 'tingl']\n",
      "1.0830729007720947\n",
      "\n",
      "81 : ['differ', 'hotel', 'motel']\n",
      "0.7644875049591064\n",
      "\n",
      "82 : ['differ', 'compani', \"'s\", 'strategi', 'busi', 'model']\n",
      "3.5996592044830322\n",
      "\n",
      "83 : ['lacquer', 'brass', 'tarnish']\n",
      "0.011064291000366211\n",
      "\n",
      "84 : ['ancient', 'egyptian', 'call', 'land', 'kemet', 'black', 'land']\n",
      "1.21376371383667\n",
      "\n",
      "85 : ['defin', 'bmt', 'medic']\n",
      "0.5518970489501953\n",
      "\n",
      "86 : ['defin', 'curvilinear']\n",
      "0.18389582633972168\n",
      "\n",
      "87 : ['defin', 'etruscan']\n",
      "0.18035268783569336\n",
      "\n",
      "88 : ['defin', 'prematur', 'babi']\n",
      "0.3612372875213623\n",
      "\n",
      "89 : ['definit', 'laudabl']\n",
      "0.3642268180847168\n",
      "\n",
      "90 : ['describ', 'muscl', 'bone', 'work', 'togeth', 'produc', 'movement']\n",
      "1.8453121185302734\n",
      "\n",
      "91 : ['prohibit', 'increas', 'crime']\n",
      "0.41379714012145996\n",
      "\n",
      "92 : ['googl', 'doc', 'auto', 'save']\n",
      "0.26401734352111816\n",
      "\n",
      "93 : ['ethambutol', 'treat', 'bone', 'infect']\n",
      "0.5149755477905273\n",
      "\n",
      "94 : ['mississippi', 'incom', 'tax']\n",
      "0.36036014556884766\n",
      "\n",
      "95 : ['dog', 'day', 'afternoon', 'mean']\n",
      "1.6491429805755615\n",
      "\n",
      "96 : ['drive', 'distanc', 'geneva', 'ny', 'syracus']\n",
      "0.29372668266296387\n",
      "\n",
      "97 : ['eat', 'food', 'consid', 'warm']\n",
      "0.9374732971191406\n",
      "\n",
      "98 : ['estar', 'mean']\n",
      "0.6848318576812744\n",
      "\n",
      "99 : ['group', 'edit', 'polici']\n",
      "0.5586628913879395\n",
      "\n",
      "100 : ['hotel', 'st.', 'loui', 'area']\n",
      "0.7007999420166016\n",
      "\n",
      "101 : ['bodi', 'oxid', 'alcohol', 'elimin']\n",
      "0.7179586887359619\n",
      "\n",
      "102 : ['natur', 'record', 'public', 'inform']\n",
      "1.329542875289917\n",
      "\n",
      "103 : ['long', 'contagi', 'catch', 'cold']\n",
      "0.5847363471984863\n",
      "\n",
      "104 : ['long', 'financi', 'institut', 'keep', 'record', 'close']\n",
      "1.4789292812347412\n",
      "\n",
      "105 : ['long', 'tick', 'surviv', 'without', 'host']\n",
      "0.8987414836883545\n",
      "\n",
      "106 : ['long', 'take', 'discov', 'rais', 'limit']\n",
      "1.5896730422973633\n",
      "\n",
      "107 : ['long', 'take', 'get', 'feel', 'back', 'surgeri']\n",
      "2.716331958770752\n",
      "\n",
      "108 : ['long', 'take', 'get', 'refund', 'petsmart']\n",
      "2.0159926414489746\n",
      "\n",
      "109 : ['long', 'take', 'remov', 'wisdom', 'tooth']\n",
      "1.4868817329406738\n",
      "\n",
      "110 : ['armi', 'date', 'websit']\n",
      "0.4267127513885498\n",
      "\n",
      "111 : ['long', 'methadon', 'stay', 'system']\n",
      "1.1453132629394531\n",
      "\n",
      "112 : ['much', 'caffein', 'twine', 'green', 'tea']\n",
      "0.6947894096374512\n",
      "\n",
      "113 : ['much', 'talent', 'director', 'get', 'paid', 'year']\n",
      "2.8582355976104736\n",
      "\n",
      "114 : ['much', 'money', 'motiv', 'speaker', 'make']\n",
      "1.7017958164215088\n",
      "\n",
      "115 : ['much', 'weight', 'usp', 'letter']\n",
      "0.8351175785064697\n",
      "\n",
      "116 : ['much', 'would', 'cost', 'instal', 'wind', 'turbin']\n",
      "1.6589231491088867\n",
      "\n",
      "117 : ['often', 'button', 'quail', 'lay', 'egg']\n",
      "0.7359275817871094\n",
      "\n",
      "118 : ['old', 'vanessa', 'redgrav']\n",
      "0.27411556243896484\n",
      "\n",
      "119 : ['open', 'heart', 'surgeri']\n",
      "0.6622123718261719\n",
      "\n",
      "120 : ['get', 'free', 'xbox', 'one', 'card']\n",
      "3.0545637607574463\n",
      "\n",
      "121 : ['uninstal', 'xbox', 'window', '10']\n",
      "0.67514967918396\n",
      "\n",
      "122 : ['ia', 'suffix', 'mean']\n",
      "0.702650785446167\n",
      "\n",
      "123 : ['caffein', 'narcot']\n",
      "0.026657581329345703\n",
      "\n",
      "124 : ['averag', 'salari', 'dental', 'hygienist', 'nebraska']\n",
      "0.7258703708648682\n",
      "\n",
      "125 : ['splitboard', 'ski']\n",
      "0.01179194450378418\n",
      "\n",
      "126 : ['duodenum', 'muscl']\n",
      "0.20322561264038086\n",
      "\n",
      "127 : ['averag', 'salari', 'canada', '1985']\n",
      "0.7804548740386963\n",
      "\n",
      "128 : ['landfil', 'hour']\n",
      "0.45763325691223145\n",
      "\n",
      "129 : ['largest', 'known', 'insect']\n",
      "0.7358908653259277\n",
      "\n",
      "130 : ['magnesium', 'definit', 'chemistri']\n",
      "0.417543888092041\n",
      "\n",
      "131 : ['mean', 'tattoo', 'around', 'eye']\n",
      "1.3048725128173828\n",
      "\n",
      "132 : ['metabol', 'diseas', 'sign', 'symptom']\n",
      "0.8807802200317383\n",
      "\n",
      "133 : ['neptun', \"'s\", 'distanc', 'earth']\n",
      "2.4200496673583984\n",
      "\n",
      "134 : ['oracl', 'bind', 'variabl', 'exampl']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6096398830413818\n",
      "\n",
      "135 : ['averag', 'wed', 'dress', 'alter', 'cost']\n",
      "1.0599071979522705\n",
      "\n",
      "136 : ['project', 'definit']\n",
      "0.5227746963500977\n",
      "\n",
      "137 : ['barclay', 'fca', 'number']\n",
      "0.677471399307251\n",
      "\n",
      "138 : ['benefit', 'polici', 'layoff']\n",
      "0.3334496021270752\n",
      "\n",
      "139 : ['hour', 'clinic']\n",
      "0.5374667644500732\n",
      "\n",
      "140 : ['symptom', 'shingl']\n",
      "0.3265407085418701\n",
      "\n",
      "141 : ['biggest', 'loser', 'challeng']\n",
      "0.11191320419311523\n",
      "\n",
      "142 : ['villag', 'burnham']\n",
      "0.045526981353759766\n",
      "\n",
      "143 : ['vitamin', 'e', 'anti', 'scar']\n",
      "0.17678189277648926\n",
      "\n",
      "144 : ['weather', 'antigua', 'novemb']\n",
      "0.2345600128173828\n",
      "\n",
      "145 : ['weather', 'novi', 'sad']\n",
      "0.1679396629333496\n",
      "\n",
      "146 : ['best', 'food', 'lower', 'cholesterol']\n",
      "1.1950798034667969\n",
      "\n",
      "147 : ['carvedilol', 'use']\n",
      "2.4370155334472656\n",
      "\n",
      "148 : ['caus', 'bruis', 'appear']\n",
      "1.0387976169586182\n",
      "\n",
      "149 : ['caus', 'muscl', 'tear']\n",
      "0.9759819507598877\n",
      "\n",
      "150 : ['counti', 'dexter', 'michigan']\n",
      "0.32037901878356934\n",
      "\n",
      "151 : ['counti', 'new', 'york', 'new', 'york']\n",
      "1.5527331829071045\n",
      "\n",
      "152 : ['counti', 'rio', 'hondo', 'tx']\n",
      "0.3124074935913086\n",
      "\n",
      "153 : ['mean', 'tsh', 'low']\n",
      "0.9261448383331299\n",
      "\n",
      "154 : ['ativan', 'caus', 'cough']\n",
      "0.802837610244751\n",
      "\n",
      "155 : ['weird', 'e', 'mean', 'math']\n",
      "0.7812392711639404\n",
      "\n",
      "156 : ['zetia', 'treat']\n",
      "0.18731093406677246\n",
      "\n",
      "157 : ['drive', 'poach']\n",
      "0.17190098762512207\n",
      "\n",
      "158 : ['food', 'take', 'plane']\n",
      "1.1988377571105957\n",
      "\n",
      "159 : ['fever', 'caus', 'miscarriag', 'earli', 'pregnanc']\n",
      "1.0933246612548828\n",
      "\n",
      "160 : ['alm']\n",
      "0.0007357597351074219\n",
      "\n",
      "161 : ['statutori', 'deed']\n",
      "0.021593332290649414\n",
      "\n",
      "162 : ['torn', 'disc']\n",
      "0.033940792083740234\n",
      "\n",
      "163 : ['aid', 'hiv']\n",
      "0.08186721801757812\n",
      "\n",
      "164 : ['mbot']\n",
      "0.00034356117248535156\n",
      "\n",
      "165 : ['chronomet', 'invent']\n",
      "0.03824353218078613\n",
      "\n",
      "166 : ['cow', 'chip']\n",
      "0.04687643051147461\n",
      "\n",
      "167 : ['crimp', 'oil']\n",
      "0.1834089756011963\n",
      "\n",
      "168 : ['uti', 'caus', 'stroke']\n",
      "0.820152997970581\n",
      "\n",
      "169 : ['mamey']\n",
      "0.00028514862060546875\n",
      "\n",
      "170 : ['onboard', 'credit', 'union']\n",
      "0.24112510681152344\n",
      "\n",
      "171 : ['rsrq']\n",
      "0.0002601146697998047\n",
      "\n",
      "172 : ['scientif', 'definit', 'cytoplasm']\n",
      "0.4283101558685303\n",
      "\n",
      "173 : ['sculptur', 'shape', 'space']\n",
      "0.26931118965148926\n",
      "\n",
      "174 : ['supplement', 'secur', 'incom', 'use']\n",
      "2.8421101570129395\n",
      "\n",
      "175 : ['actor', 'color']\n",
      "0.28246641159057617\n",
      "\n",
      "176 : ['best', 'music', 'maker']\n",
      "0.6702547073364258\n",
      "\n",
      "177 : ['botan', 'name', 'mango']\n",
      "0.7003631591796875\n",
      "\n",
      "178 : ['data', 'rate', 'sdtv']\n",
      "0.6909916400909424\n",
      "\n",
      "179 : ['electr', 'field']\n",
      "0.28151822090148926\n",
      "\n",
      "180 : ['symptom', 'croup']\n",
      "0.3163907527923584\n",
      "\n",
      "181 : ['caus', 'short', 'breath', 'exert']\n",
      "1.008570909500122\n",
      "\n",
      "182 : ['temperatur', 'venic', 'fl']\n",
      "0.290454626083374\n",
      "\n",
      "183 : ['caus', 'ga', 'larg', 'intestin']\n",
      "1.3012464046478271\n",
      "\n",
      "184 : ['metal', 'hip', 'replac', 'made']\n",
      "0.7259392738342285\n",
      "\n",
      "185 : ['brain', 'protein', 'caus', 'dementia']\n",
      "1.058377742767334\n",
      "\n",
      "186 : ['caus', 'stroke']\n",
      "0.8041279315948486\n",
      "\n",
      "187 : ['type', 'conflict', 'della', 'face', 'henri', 'gift', 'magi']\n",
      "0.936511754989624\n",
      "\n",
      "188 : ['type', 'tissu', 'bronchiol']\n",
      "0.8437681198120117\n",
      "\n",
      "189 : ['chicken', 'food', 'wikipedia']\n",
      "0.516890287399292\n",
      "\n",
      "190 : ['darwin', \"'s\", 'greatest', 'contribut', 'evolutionari', 'theori']\n",
      "2.387911319732666\n",
      "\n",
      "191 : ['famili', 'feud', 'come']\n",
      "0.778294563293457\n",
      "\n",
      "192 : ['rock', 'n', 'roll', 'begin']\n",
      "0.47464513778686523\n",
      "\n",
      "193 : ['ace', 'hardwar', 'open']\n",
      "0.3794829845428467\n",
      "\n",
      "194 : ['berlin', 'center']\n",
      "0.2578268051147461\n",
      "\n",
      "195 : ['kampuchea']\n",
      "0.00037169456481933594\n",
      "\n",
      "196 : ['convert', 'sq', 'meter', 'sq', 'inch']\n",
      "0.328763484954834\n",
      "\n",
      "197 : ['show', 'shameless', 'film']\n",
      "0.5424480438232422\n",
      "\n",
      "198 : ['velbert']\n",
      "0.0002608299255371094\n",
      "\n",
      "199 : ['definit', 'attempt', 'arson']\n",
      "0.424619197845459\n",
      "\n",
      "Total time to process the queries: 151.18924403190613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_start_time = time.time()\n",
    "\n",
    "queries_matches = []\n",
    "\n",
    "for i in range(200):\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"{} : {}\".format(i, stemmed_queries[i]))\n",
    "    \n",
    "    queries_matches.append(find_related_documents(stemmed_queries[i]))\n",
    "\n",
    "    print(\"{}\\n\".format(time.time() - start_time))\n",
    "    \n",
    "print(\"Total time to process the queries: {}\\n\".format(time.time() - process_start_time))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f00c15",
   "metadata": {},
   "source": [
    "### Now save the results in the TREC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34d27727",
   "metadata": {},
   "outputs": [],
   "source": [
    "TREC_RESULT_LINE_FORMAT=\"{}\\tQ0\\t{}\\t{}\\t{}\\tboolean\\n\"\n",
    "MAX_RESULTS_TO_SAVE=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04bb5f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trec_format(queries_matches, query_ids, output_filename, verbose=False):\n",
    "    \n",
    "    with open(output_filename, 'w') as outputFile:\n",
    "        for i, query_result in enumerate(queries_matches):\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Saving query {}\\n{}:\".format(i, query_text[i]))\n",
    "            \n",
    "            relevant_docs = np.array(list(query_result.keys()))\n",
    "            relevant_docs_scores = np.array(list(query_result.values()))\n",
    "            \n",
    "            relevant_docs_order = np.argsort(relevant_docs_scores)[::-1]\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"relevant_docs.shape={}\".format(relevant_docs.shape))\n",
    "            \n",
    "            relevant_docs_final_result = relevant_docs[relevant_docs_order]\n",
    "            relevant_docs_final_score = relevant_docs_scores[relevant_docs_order]\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"relevant_docs_final_result: {}\\n\\n\".format(relevant_docs_final_result))\n",
    "            \n",
    "            for j, each_match in enumerate(relevant_docs_final_result[:MAX_RESULTS_TO_SAVE]):\n",
    "                outputFile.write(TREC_RESULT_LINE_FORMAT.format(query_ids[i], each_match, j, relevant_docs_final_score[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7179cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_filename = os.path.join(TREC_DL_2020_RUN_FOLDER, TREC_DL_2020_RUN_FORMAT.format(datetime.now().strftime(\"%Y%m%d_%H%M%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f302203",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_trec_format(queries_matches, query_index, run_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5711cee",
   "metadata": {},
   "source": [
    "### Now, apply the TREC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b3bef13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map                   \tall\t0.0983\r\n",
      "recip_rank            \tall\t0.3632\r\n",
      "recall_1000           \tall\t0.5019\r\n",
      "ndcg_cut_10           \tall\t0.1740\r\n"
     ]
    }
   ],
   "source": [
    "!{TREC_EVAL_FULLPATH} -c -mrecall.1000 -mmap -mndcg_cut.10 -mrecip_rank \\\n",
    "    {TREC_DL_2020_QRELS} {run_filename}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
